# https://github.com/big-data-europe/docker-spark
version: '3'
services:
    sparkmaster:
        image: bde2020/spark-master:3.0.1-hadoop3.2
        container_name: sparkmaster
        networks:
            - mynet
        environment:
            TZ: Europe/Madrid
            INIT_DAEMON_STEP: setup_spark
            SPARK_PUBLIC_DNS: sparkmaster
            constraint: node==master
        env_file:
            - ./hadoop.env

    sparkworker1:
        image: bde2020/spark-worker:3.0.1-hadoop3.2
        container_name: sparkworker1
        hostname: sparkworker1
        networks:
            - mynet
        depends_on:
            - sparkmaster
        environment:
            TZ: Europe/Madrid
            SPARK_MASTER: spark://sparkmaster:7077
            SPARK_PUBLIC_DNS: sparkworker1
            constraint: node==sparkworker1
        env_file:
            - ./hadoop.env

    sparkworker2:
        image: bde2020/spark-worker:3.0.1-hadoop3.2
        container_name: sparkworker2
        hostname: sparkworker2
        networks:
            - mynet
        depends_on:
            - sparkmaster
        ports:
            - "8082:8081"
        environment:
            TZ: Europe/Madrid
            SPARK_MASTER: spark://sparkmaster:7077
            SPARK_PUBLIC_DNS: sparkworker2
            constraint: node==sparkworker2

networks:
    mynet:
        name: mynet
